# Data Engineering ETL

## ğŸ“Œ Objectif du projet
Lâ€™objectif Ã©tait de mettre en place un pipeline complet permettant de :
- Nettoyer des fichiers CSV bruts (donnÃ©es clients & Ã©vÃ©nements).
- VÃ©rifier la validitÃ© et la cohÃ©rence des donnÃ©es (formats, types, UUID, etc.).
- Convertir les fichiers nettoyÃ©s en **Parquet** (format optimisÃ©).
- ConcatÃ©ner lâ€™ensemble des fichiers dans un seul dataset structurÃ©.
- Charger ces donnÃ©es dans une base **PostgreSQL**.
- Visualiser et manipuler facilement les donnÃ©es avec **DBeaver**.

---

## âš™ï¸ Technologies utilisÃ©es
- **Python 3** : nettoyage, transformation et insertion en base.  
  - Pandas, Numpy â†’ manipulation des datasets.  
  - Psycopg2 â†’ connexion et insertion dans PostgreSQL.  
- **PostgreSQL** : stockage des donnÃ©es propres et consolidÃ©es.  
- **DBeaver** : outil graphique pour explorer les tables et exÃ©cuter des requÃªtes SQL.  

---

## ğŸ“š Ce que jâ€™ai appris
- CrÃ©ation et gestion de tables PostgreSQL (clÃ©s primaires, types de colonnes).  
- Manipulation avancÃ©e de DataFrames avec **Pandas**.  
- Conversion CSV â†’ Parquet pour optimiser la performance.  
- DÃ©tection et suppression des doublons dans une base SQL.  
- Gestion de lâ€™insertion massive de donnÃ©es avec `execute_values` (batch insert).  
- Utilisation de **DBeaver** pour visualiser efficacement les donnÃ©es stockÃ©es.  

---

## ğŸš€ Workflow du projet
1. **Nettoyage** : vÃ©rification des colonnes, conversion des types, correction des UUID.  
2. **Transformation** : sauvegarde en fichiers Parquet, tri par annÃ©e/mois.  
3. **ConcatÃ©nation** : fusion de tous les fichiers dans un seul DataFrame `customers`.  
4. **Insertion SQL** : crÃ©ation de la table PostgreSQL et insertion des enregistrements.  
5. **Visualisation** : exploration de la base avec DBeaver.  

---

## ğŸ“‚ Structure principale
- `clean_export_data.py` â†’ script principal de nettoyage et export vers PostgreSQL.  
- `items_table.py` â†’ crÃ©ation et import de la table `items`.  
- `automatisation_csv.py` â†’ automatisation du pipeline complet.  

---

## âœ… RÃ©sultat final
Une base PostgreSQL consolidÃ©e contenant lâ€™ensemble des Ã©vÃ©nements clients, nettoyÃ©e, sans doublons, et prÃªte Ã  Ãªtre utilisÃ©e pour des analyses plus avancÃ©es.
